{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Anscombe Transform","text":"<p>Zarr V2 and V3 codecs for compressing photon-limited movies using the Anscombe Transform.</p>"},{"location":"#what-is-it","title":"What is it?","text":"<p>This codec is designed for compressing movies with Poisson noise, which are produced by photon-limited modalities such as:</p> <ul> <li>Multiphoton microscopy</li> <li>Radiography</li> <li>Astronomy</li> </ul>"},{"location":"#how-it-works","title":"How it works","text":"<p>The codec re-quantizes grayscale data efficiently using a square-root-like transformation to equalize noise variance across grayscale levels: the Anscombe Transform. This results in:</p> <ul> <li>Fewer unique grayscale levels</li> <li>Significant improvements in data compressibility</li> <li>No sacrifice to signal accuracy</li> </ul>"},{"location":"#requirements","title":"Requirements","text":"<p>To use the codec, you need to provide two pieces of information:</p> <ol> <li><code>zero_level</code>: The input value corresponding to the absence of light</li> <li><code>conversion_gain</code> (also called <code>photon_sensitivity</code>): The conversion factor from signal levels to photon counts</li> </ol> <p>The codec assumes that the video is linearly encoded with a potential offset and that these parameters can be accurately estimated from the data.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>\u2705 Zarr V2 support via <code>numcodecs</code> interface</li> <li>\u2705 Zarr V3 support via <code>ArrayArrayCodec</code> interface</li> <li>\u2705 Automatic parameter estimation from data</li> <li>\u2705 Lossless compression for photon-limited data</li> <li>\u2705 Python 3.11+ support</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import zarr\nimport numpy as np\nfrom anscombe_transform import AnscombeTransformV3\n\n# Create sample data with Poisson noise\ndata = np.random.poisson(lam=50, size=(100, 512, 512)).astype('int16')\n\n# Create Zarr array with Anscombe codec\nstore = zarr.storage.MemoryStore()\narr = zarr.create(\n    store=store,\n    shape=data.shape,\n    chunks=(10, 512, 512),\n    dtype='int16',\n    filters=[AnscombeTransformV3(zero_level=100, conversion_gain=2.5)],\n    zarr_format=3\n)\n\n# Write and read data\narr[:] = data\nrecovered = arr[:]\n</code></pre>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Installation Guide</li> <li>Quick Start Tutorial</li> <li>User Guide</li> <li>API Reference</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to the Anscombe Transform codec! This guide will help you get started.</p>"},{"location":"contributing/#development-setup","title":"Development Setup","text":""},{"location":"contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python &gt;= 3.11</li> <li>Hatch for environment management</li> <li>Git</li> </ul>"},{"location":"contributing/#getting-started","title":"Getting Started","text":"<ol> <li>Fork and clone the repository</li> </ol> <pre><code>git clone https://github.com/YOUR_USERNAME/anscombe-transform.git\ncd anscombe-transform\n</code></pre> <ol> <li>Install Hatch</li> </ol> <pre><code>pip install hatch\n</code></pre> <ol> <li>Create a development environment</li> </ol> <pre><code># See available environments\nhatch env show\n\n# Enter a test environment\nhatch shell test.py3.11-2.2\n</code></pre> <ol> <li>Run tests</li> </ol> <pre><code># Run all tests\nhatch run test:pytest tests/\n\n# Run specific test file\nhatch run test:pytest tests/test_codec.py\n\n# Run with coverage\nhatch run test:pytest tests/ --cov=src/anscombe_transform\n</code></pre>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"contributing/#making-changes","title":"Making Changes","text":"<ol> <li> <p>Create a new branch for your feature or fix: <pre><code>git checkout -b feature/my-new-feature\n</code></pre></p> </li> <li> <p>Make your changes following the coding standards below</p> </li> <li> <p>Run tests to ensure everything works: <pre><code>hatch run test:pytest tests/\n</code></pre></p> </li> <li> <p>Run linting and formatting: <pre><code>hatch run test:ruff check src/ tests/\nhatch run test:ruff format src/ tests/\n</code></pre></p> </li> </ol>"},{"location":"contributing/#testing","title":"Testing","text":"<p>The project uses pytest for testing. Tests are organized in the <code>tests/</code> directory:</p> <ul> <li><code>test_codec.py</code> - Direct codec encode/decode tests</li> <li><code>test_zarr.py</code> - Zarr integration tests for V2 and V3</li> <li><code>test_notebooks.py</code> - Notebook execution tests</li> </ul> <p>Writing Tests</p> <ul> <li>Use the <code>nearly_equal()</code> fixture for comparing arrays with tolerance</li> <li>Test with synthetic Poisson-distributed data</li> <li>Cover both Zarr V2 and V3 implementations</li> <li>Include edge cases (zero values, large values, etc.)</li> </ul> <p>Example: <pre><code>def test_my_feature(nearly_equal):\n    # Create test data\n    data = np.random.poisson(lam=50, size=(10, 100, 100)).astype('int16')\n\n    # Test your feature\n    result = my_function(data)\n\n    # Assert with tolerance\n    assert nearly_equal(result, expected, conversion_gain=2.5)\n</code></pre></p>"},{"location":"contributing/#running-tests-across-environments","title":"Running Tests Across Environments","text":"<p>Test against multiple Python and NumPy versions:</p> <pre><code># Run on all environments\nhatch run test:pytest tests/\n\n# Run on specific Python version\nhatch run test.py3.12-2.2:pytest tests/\n\n# Test against upstream dependencies\nhatch run upstream:pytest tests/\n</code></pre>"},{"location":"contributing/#coding-standards","title":"Coding Standards","text":""},{"location":"contributing/#style-guide","title":"Style Guide","text":"<ul> <li>Follow PEP 8</li> <li>Use Ruff for linting and formatting</li> <li>Maximum line length: 100 characters</li> <li>Use type hints for all public functions</li> </ul>"},{"location":"contributing/#documentation","title":"Documentation","text":"<ul> <li>Write docstrings for all public functions and classes</li> <li>Use NumPy-style docstrings</li> <li>Include examples in docstrings where helpful</li> <li>Update relevant documentation in <code>docs/</code></li> </ul> <p>Example docstring: <pre><code>def my_function(data: np.ndarray, param: float) -&gt; np.ndarray:\n    \"\"\"\n    Brief description of what this function does.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        Description of data parameter\n    param : float\n        Description of param parameter\n\n    Returns\n    -------\n    np.ndarray\n        Description of return value\n\n    Examples\n    --------\n    &gt;&gt;&gt; data = np.array([1, 2, 3])\n    &gt;&gt;&gt; result = my_function(data, 2.5)\n    \"\"\"\n    pass\n</code></pre></p>"},{"location":"contributing/#type-hints","title":"Type Hints","text":"<p>Use type hints for function signatures:</p> <pre><code>from typing import Optional, Union\nimport numpy as np\n\ndef process_data(\n    data: np.ndarray,\n    conversion_gain: float,\n    zero_level: Optional[float] = None\n) -&gt; tuple[np.ndarray, dict]:\n    \"\"\"Process data with optional parameters.\"\"\"\n    pass\n</code></pre>"},{"location":"contributing/#submitting-changes","title":"Submitting Changes","text":""},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li> <p>Update documentation if you've changed APIs or added features</p> </li> <li> <p>Add tests for new functionality</p> </li> <li> <p>Update CHANGELOG if significant changes were made</p> </li> <li> <p>Push your branch to your fork: <pre><code>git push origin feature/my-new-feature\n</code></pre></p> </li> <li> <p>Open a Pull Request on GitHub:</p> </li> <li>Provide a clear description of the changes</li> <li>Reference any related issues</li> <li>Ensure CI tests pass</li> </ol>"},{"location":"contributing/#pull-request-checklist","title":"Pull Request Checklist","text":"<p>Before submitting, verify:</p> <ul> <li>[ ] Tests pass locally</li> <li>[ ] New tests added for new features</li> <li>[ ] Documentation updated</li> <li>[ ] Code follows style guidelines</li> <li>[ ] Type hints added</li> <li>[ ] Docstrings written</li> <li>[ ] CHANGELOG updated (if applicable)</li> </ul>"},{"location":"contributing/#building-documentation","title":"Building Documentation","text":""},{"location":"contributing/#local-documentation-server","title":"Local Documentation Server","text":"<pre><code># Install docs dependencies\nhatch run docs:mkdocs serve\n\n# View at http://127.0.0.1:8000\n</code></pre>"},{"location":"contributing/#building-documentation_1","title":"Building Documentation","text":"<pre><code># Build static site\nhatch run docs:mkdocs build\n\n# Output in site/\n</code></pre>"},{"location":"contributing/#project-structure","title":"Project Structure","text":"<pre><code>anscombe-transform/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 anscombe_transform/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 codec.py         # Main codec implementations\n\u2502       \u251c\u2500\u2500 estimate.py      # Parameter estimation\n\u2502       \u2514\u2500\u2500 version.py       # Version info (auto-generated)\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 conftest.py         # Pytest fixtures\n\u2502   \u251c\u2500\u2500 test_codec.py       # Codec tests\n\u2502   \u251c\u2500\u2500 test_zarr.py        # Zarr integration tests\n\u2502   \u2514\u2500\u2500 test_notebooks.py   # Notebook tests\n\u251c\u2500\u2500 docs/                   # Documentation source\n\u251c\u2500\u2500 examples/               # Example notebooks\n\u251c\u2500\u2500 pyproject.toml          # Project configuration\n\u2514\u2500\u2500 mkdocs.yml             # Documentation config\n</code></pre>"},{"location":"contributing/#getting-help","title":"Getting Help","text":"<ul> <li>Questions? Open a GitHub Discussion</li> <li>Bug reports? Open an Issue</li> <li>Need to chat? Contact the maintainers</li> </ul>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>Please be respectful and constructive in all interactions. We aim to foster an inclusive and welcoming community.</p>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the MIT License.</p>"},{"location":"api/codec/","title":"Codec API Reference","text":"<p>This page documents the codec implementations for both Zarr V2 and V3.</p>"},{"location":"api/codec/#anscombetransformv3","title":"AnscombeTransformV3","text":""},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV3","title":"<code>AnscombeTransformV3</code>  <code>dataclass</code>","text":"<p>               Bases: <code>ArrayArrayCodec</code></p> <p>Zarr v3 codec for Anscombe Transform for photon-limited data.</p> <p>The codec assumes input data has linear encoding with Poisson noise, typically from photon-limited imaging modalities.</p> <p>Attributes:</p> Name Type Description <code>zero_level</code> <code>int</code> <p>Signal level when no photons are recorded.</p> <code>conversion_gain</code> <code>float</code> <p>Signal intensity increase per photon.</p> <code>encoded_dtype</code> <code>str</code> <p>Data type for encoded values (default: \"uint8\").</p> <code>decoded_dtype</code> <code>str</code> <p>Data type for decoded values (default: \"int16\").</p> <code>is_fixed_size</code> <code>bool</code> <p>Whether the codec produces fixed-size output (default: True).</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>@dataclass(frozen=True, slots=True)\nclass AnscombeTransformV3(ArrayArrayCodec):\n    \"\"\"\n    Zarr v3 codec for Anscombe Transform for photon-limited data.\n\n    The codec assumes input data has linear encoding with Poisson noise,\n    typically from photon-limited imaging modalities.\n\n    Attributes\n    ----------\n    zero_level : int\n        Signal level when no photons are recorded.\n    conversion_gain : float\n        Signal intensity increase per photon.\n    encoded_dtype : str\n        Data type for encoded values (default: \"uint8\").\n    decoded_dtype : str\n        Data type for decoded values (default: \"int16\").\n    is_fixed_size : bool\n        Whether the codec produces fixed-size output (default: True).\n    \"\"\"\n\n    zero_level: int\n    conversion_gain: float\n    encoded_dtype: str = \"uint8\"\n    decoded_dtype: str = \"int16\"\n    is_fixed_size: bool = True\n\n    @classmethod\n    def from_dict(cls, data: dict) -&gt; Self:\n        \"\"\"\n        Create codec instance from configuration dictionary.\n\n        Parameters\n        ----------\n        data : dict\n            Configuration dictionary with 'configuration' key containing codec parameters.\n\n        Returns\n        -------\n        AnscombeTransformV3\n            New codec instance.\n        \"\"\"\n        config = data.get(\"configuration\", {})\n        return cls(\n            zero_level=config[\"zero_level\"],\n            conversion_gain=config[\"conversion_gain\"],\n            encoded_dtype=config.get(\"encoded_dtype\", \"uint8\"),\n            decoded_dtype=config.get(\"decoded_dtype\", \"int16\"),\n        )\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"\n        Convert codec to configuration dictionary.\n\n        Returns\n        -------\n        dict\n            Configuration dictionary with codec name and parameters.\n        \"\"\"\n        return {\n            \"name\": \"anscombe-v1\",\n            \"configuration\": {\n                \"zero_level\": self.zero_level,\n                \"conversion_gain\": self.conversion_gain,\n                \"encoded_dtype\": self.encoded_dtype,\n                \"decoded_dtype\": self.decoded_dtype,\n            },\n        }\n\n    def resolve_metadata(self, chunk_spec: ArraySpec) -&gt; ArraySpec:\n        \"\"\"\n        Resolve metadata for encoded output.\n\n        Parameters\n        ----------\n        chunk_spec : ArraySpec\n            Input chunk specification.\n\n        Returns\n        -------\n        ArraySpec\n            Output chunk specification with updated dtype.\n        \"\"\"\n        return ArraySpec(\n            shape=chunk_spec.shape,\n            dtype=parse_dtype(np.dtype(self.encoded_dtype), zarr_format=3),\n            fill_value=chunk_spec.fill_value,\n            config=chunk_spec.config,\n            prototype=chunk_spec.prototype,\n        )\n\n    def _encode(self, buf: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Encode data synchronously for direct use.\n\n        Parameters\n        ----------\n        buf : np.ndarray\n            Input array to encode.\n\n        Returns\n        -------\n        np.ndarray\n            Encoded array.\n        \"\"\"\n        return encode(\n            buf,\n            conversion_gain=self.conversion_gain,\n            zero_level=self.zero_level,\n            encoded_dtype=self.encoded_dtype,\n        )\n\n    def _decode(self, buf: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Decode data synchronously for direct use.\n\n        Parameters\n        ----------\n        buf : np.ndarray\n            Encoded buffer to decode.\n\n        Returns\n        -------\n        np.ndarray\n            Decoded array.\n        \"\"\"\n        return decode(\n            buf.tobytes(),\n            conversion_gain=self.conversion_gain,\n            zero_level=self.zero_level,\n            encoded_dtype=self.encoded_dtype,\n            decoded_dtype=self.decoded_dtype,\n        )\n\n    async def _encode_single(\n        self,\n        chunk_array,\n        chunk_spec,\n    ):\n        \"\"\"\n        Encode a single chunk using Anscombe transform.\n\n        Parameters\n        ----------\n        chunk_array : NDBuffer\n            Input chunk to encode.\n        chunk_spec : ArraySpec\n            Chunk specification.\n\n        Returns\n        -------\n        NDBuffer\n            Encoded chunk.\n        \"\"\"\n        # Convert NDBuffer to numpy array\n        data = chunk_array.as_numpy_array()\n\n        # Apply encoding\n        encoded = self._encode(data)\n\n        # Return as NDBuffer\n        return chunk_array.from_numpy_array(encoded)\n\n    async def _decode_single(\n        self,\n        chunk_array,\n        chunk_spec,\n    ):\n        \"\"\"\n        Decode a single chunk using inverse Anscombe transform.\n\n        Parameters\n        ----------\n        chunk_array : NDBuffer\n            Encoded chunk to decode.\n        chunk_spec : ArraySpec\n            Chunk specification.\n\n        Returns\n        -------\n        NDBuffer\n            Decoded chunk.\n        \"\"\"\n        # Convert NDBuffer to numpy array\n        data = chunk_array.as_numpy_array()\n\n        # Apply decoding\n        decoded = self._decode(data)\n\n        # Reshape to original shape\n        decoded = decoded.reshape(chunk_spec.shape)\n\n        # Return as NDBuffer\n        return chunk_array.from_numpy_array(decoded)\n</code></pre>"},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV3.from_dict","title":"<code>from_dict(data)</code>  <code>classmethod</code>","text":"<p>Create codec instance from configuration dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Configuration dictionary with 'configuration' key containing codec parameters.</p> required <p>Returns:</p> Type Description <code>AnscombeTransformV3</code> <p>New codec instance.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict) -&gt; Self:\n    \"\"\"\n    Create codec instance from configuration dictionary.\n\n    Parameters\n    ----------\n    data : dict\n        Configuration dictionary with 'configuration' key containing codec parameters.\n\n    Returns\n    -------\n    AnscombeTransformV3\n        New codec instance.\n    \"\"\"\n    config = data.get(\"configuration\", {})\n    return cls(\n        zero_level=config[\"zero_level\"],\n        conversion_gain=config[\"conversion_gain\"],\n        encoded_dtype=config.get(\"encoded_dtype\", \"uint8\"),\n        decoded_dtype=config.get(\"decoded_dtype\", \"int16\"),\n    )\n</code></pre>"},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV3.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert codec to configuration dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Configuration dictionary with codec name and parameters.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"\n    Convert codec to configuration dictionary.\n\n    Returns\n    -------\n    dict\n        Configuration dictionary with codec name and parameters.\n    \"\"\"\n    return {\n        \"name\": \"anscombe-v1\",\n        \"configuration\": {\n            \"zero_level\": self.zero_level,\n            \"conversion_gain\": self.conversion_gain,\n            \"encoded_dtype\": self.encoded_dtype,\n            \"decoded_dtype\": self.decoded_dtype,\n        },\n    }\n</code></pre>"},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV3.resolve_metadata","title":"<code>resolve_metadata(chunk_spec)</code>","text":"<p>Resolve metadata for encoded output.</p> <p>Parameters:</p> Name Type Description Default <code>chunk_spec</code> <code>ArraySpec</code> <p>Input chunk specification.</p> required <p>Returns:</p> Type Description <code>ArraySpec</code> <p>Output chunk specification with updated dtype.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def resolve_metadata(self, chunk_spec: ArraySpec) -&gt; ArraySpec:\n    \"\"\"\n    Resolve metadata for encoded output.\n\n    Parameters\n    ----------\n    chunk_spec : ArraySpec\n        Input chunk specification.\n\n    Returns\n    -------\n    ArraySpec\n        Output chunk specification with updated dtype.\n    \"\"\"\n    return ArraySpec(\n        shape=chunk_spec.shape,\n        dtype=parse_dtype(np.dtype(self.encoded_dtype), zarr_format=3),\n        fill_value=chunk_spec.fill_value,\n        config=chunk_spec.config,\n        prototype=chunk_spec.prototype,\n    )\n</code></pre>"},{"location":"api/codec/#anscombetransformv2","title":"AnscombeTransformV2","text":""},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV2","title":"<code>AnscombeTransformV2</code>  <code>dataclass</code>","text":"<p>Zarr v2 codec for Anscombe Transform for photon-limited data.</p> <p>The codec assumes input data has linear encoding with Poisson noise, typically from photon-limited imaging modalities.</p> <p>Attributes:</p> Name Type Description <code>codec_id</code> <code>str</code> <p>Codec identifier (\"anscombe-v1\").</p> <code>zero_level</code> <code>int</code> <p>Signal level when no photons are recorded.</p> <code>conversion_gain</code> <code>float</code> <p>Signal intensity increase per photon.</p> <code>encoded_dtype</code> <code>str</code> <p>Data type for encoded values (default: \"uint8\").</p> <code>decoded_dtype</code> <code>str</code> <p>Data type for decoded values (default: \"int16\").</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>@dataclass(frozen=True, slots=True)\nclass AnscombeTransformV2:\n    \"\"\"\n    Zarr v2 codec for Anscombe Transform for photon-limited data.\n\n    The codec assumes input data has linear encoding with Poisson noise,\n    typically from photon-limited imaging modalities.\n\n    Attributes\n    ----------\n    codec_id : str\n        Codec identifier (\"anscombe-v1\").\n    zero_level : int\n        Signal level when no photons are recorded.\n    conversion_gain : float\n        Signal intensity increase per photon.\n    encoded_dtype : str\n        Data type for encoded values (default: \"uint8\").\n    decoded_dtype : str\n        Data type for decoded values (default: \"int16\").\n    \"\"\"\n\n    codec_id: ClassVar[Literal[\"anscombe-v1\"]] = \"anscombe-v1\"\n    zero_level: int\n    conversion_gain: float\n    encoded_dtype: str = \"uint8\"\n    decoded_dtype: str = \"int16\"\n\n    def encode(self, buf: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Encode data using Anscombe transform.\n\n        Parameters\n        ----------\n        buf : np.ndarray\n            Input array to encode.\n\n        Returns\n        -------\n        np.ndarray\n            Encoded array.\n        \"\"\"\n        return encode(\n            buf,\n            conversion_gain=self.conversion_gain,\n            zero_level=self.zero_level,\n            encoded_dtype=self.encoded_dtype,\n        )\n\n    def decode(self, buf: bytes, out: object | None = None) -&gt; np.ndarray:\n        \"\"\"\n        Decode data using inverse Anscombe transform.\n\n        Parameters\n        ----------\n        buf : bytes\n            Encoded buffer to decode.\n        out : object or None, optional\n            Output buffer (unused), by default None.\n\n        Returns\n        -------\n        np.ndarray\n            Decoded array.\n        \"\"\"\n        return decode(\n            buf,\n            conversion_gain=self.conversion_gain,\n            zero_level=self.zero_level,\n            encoded_dtype=self.encoded_dtype,\n            decoded_dtype=self.decoded_dtype,\n        )\n\n    def get_config(self) -&gt; AnscomeCodecJSON_V2:\n        \"\"\"\n        Get codec configuration dictionary.\n\n        Returns\n        -------\n        dict\n            Configuration dictionary with codec ID and parameters.\n        \"\"\"\n        return {\n            \"id\": self.codec_id,\n            \"zero_level\": self.zero_level,\n            \"conversion_gain\": self.conversion_gain,\n        }\n\n    @classmethod\n    def from_config(cls, config: AnscomeCodecJSON_V2) -&gt; Self:\n        \"\"\"\n        Create codec instance from configuration dictionary.\n\n        Parameters\n        ----------\n        config : dict\n            Configuration dictionary with 'zero_level' and 'conversion_gain' keys.\n\n        Returns\n        -------\n        AnscombeTransformV2\n            New codec instance.\n        \"\"\"\n        return cls(zero_level=config[\"zero_level\"], conversion_gain=config[\"conversion_gain\"])\n</code></pre>"},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV2.encode","title":"<code>encode(buf)</code>","text":"<p>Encode data using Anscombe transform.</p> <p>Parameters:</p> Name Type Description Default <code>buf</code> <code>ndarray</code> <p>Input array to encode.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Encoded array.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def encode(self, buf: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Encode data using Anscombe transform.\n\n    Parameters\n    ----------\n    buf : np.ndarray\n        Input array to encode.\n\n    Returns\n    -------\n    np.ndarray\n        Encoded array.\n    \"\"\"\n    return encode(\n        buf,\n        conversion_gain=self.conversion_gain,\n        zero_level=self.zero_level,\n        encoded_dtype=self.encoded_dtype,\n    )\n</code></pre>"},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV2.decode","title":"<code>decode(buf, out=None)</code>","text":"<p>Decode data using inverse Anscombe transform.</p> <p>Parameters:</p> Name Type Description Default <code>buf</code> <code>bytes</code> <p>Encoded buffer to decode.</p> required <code>out</code> <code>object or None</code> <p>Output buffer (unused), by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Decoded array.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def decode(self, buf: bytes, out: object | None = None) -&gt; np.ndarray:\n    \"\"\"\n    Decode data using inverse Anscombe transform.\n\n    Parameters\n    ----------\n    buf : bytes\n        Encoded buffer to decode.\n    out : object or None, optional\n        Output buffer (unused), by default None.\n\n    Returns\n    -------\n    np.ndarray\n        Decoded array.\n    \"\"\"\n    return decode(\n        buf,\n        conversion_gain=self.conversion_gain,\n        zero_level=self.zero_level,\n        encoded_dtype=self.encoded_dtype,\n        decoded_dtype=self.decoded_dtype,\n    )\n</code></pre>"},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV2.get_config","title":"<code>get_config()</code>","text":"<p>Get codec configuration dictionary.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Configuration dictionary with codec ID and parameters.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def get_config(self) -&gt; AnscomeCodecJSON_V2:\n    \"\"\"\n    Get codec configuration dictionary.\n\n    Returns\n    -------\n    dict\n        Configuration dictionary with codec ID and parameters.\n    \"\"\"\n    return {\n        \"id\": self.codec_id,\n        \"zero_level\": self.zero_level,\n        \"conversion_gain\": self.conversion_gain,\n    }\n</code></pre>"},{"location":"api/codec/#anscombe_transform.codec.AnscombeTransformV2.from_config","title":"<code>from_config(config)</code>  <code>classmethod</code>","text":"<p>Create codec instance from configuration dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Configuration dictionary with 'zero_level' and 'conversion_gain' keys.</p> required <p>Returns:</p> Type Description <code>AnscombeTransformV2</code> <p>New codec instance.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>@classmethod\ndef from_config(cls, config: AnscomeCodecJSON_V2) -&gt; Self:\n    \"\"\"\n    Create codec instance from configuration dictionary.\n\n    Parameters\n    ----------\n    config : dict\n        Configuration dictionary with 'zero_level' and 'conversion_gain' keys.\n\n    Returns\n    -------\n    AnscombeTransformV2\n        New codec instance.\n    \"\"\"\n    return cls(zero_level=config[\"zero_level\"], conversion_gain=config[\"conversion_gain\"])\n</code></pre>"},{"location":"api/codec/#core-functions","title":"Core Functions","text":""},{"location":"api/codec/#encode","title":"encode","text":""},{"location":"api/codec/#anscombe_transform.codec.encode","title":"<code>encode(buf, *, conversion_gain, zero_level, encoded_dtype)</code>","text":"<p>Encode an array using the Anscombe transform.</p> <p>Parameters:</p> Name Type Description Default <code>buf</code> <code>ndarray</code> <p>Input array to encode.</p> required <code>conversion_gain</code> <code>float</code> <p>Signal intensity increase per photon.</p> required <code>zero_level</code> <code>int</code> <p>Signal level when no photons are recorded.</p> required <code>encoded_dtype</code> <code>str</code> <p>NumPy dtype string for encoded output.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Encoded array with variance-stabilized values.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def encode(\n    buf: np.ndarray, *, conversion_gain: float, zero_level: int, encoded_dtype: str\n) -&gt; np.ndarray:\n    \"\"\"\n    Encode an array using the Anscombe transform.\n\n    Parameters\n    ----------\n    buf : np.ndarray\n        Input array to encode.\n    conversion_gain : float\n        Signal intensity increase per photon.\n    zero_level : int\n        Signal level when no photons are recorded.\n    encoded_dtype : str\n        NumPy dtype string for encoded output.\n\n    Returns\n    -------\n    np.ndarray\n        Encoded array with variance-stabilized values.\n    \"\"\"\n    lut = make_anscombe_lookup(\n        conversion_gain,\n        output_type=encoded_dtype,\n        zero_level=zero_level,\n    )\n    encoded = lookup(buf, lut)\n    return encoded.astype(encoded_dtype)\n</code></pre>"},{"location":"api/codec/#decode","title":"decode","text":""},{"location":"api/codec/#anscombe_transform.codec.decode","title":"<code>decode(buf, *, conversion_gain, zero_level, encoded_dtype, decoded_dtype)</code>","text":"<p>Decode an array using the inverse Anscombe transform.</p> <p>Parameters:</p> Name Type Description Default <code>buf</code> <code>bytes or ndarray</code> <p>Encoded buffer to decode.</p> required <code>conversion_gain</code> <code>float</code> <p>Signal intensity increase per photon.</p> required <code>zero_level</code> <code>int</code> <p>Signal level when no photons are recorded.</p> required <code>encoded_dtype</code> <code>DtypeLike</code> <p>NumPy dtype of encoded data.</p> required <code>decoded_dtype</code> <code>DtypeLike</code> <p>NumPy dtype for decoded output.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Decoded array with original value scale.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def decode(\n    buf: bytes | np.ndarray,\n    *,\n    conversion_gain: float,\n    zero_level: int,\n    encoded_dtype: npt.DtypeLike,\n    decoded_dtype: npt.DTypeLike,\n) -&gt; np.ndarray:\n    \"\"\"\n    Decode an array using the inverse Anscombe transform.\n\n    Parameters\n    ----------\n    buf : bytes or np.ndarray\n        Encoded buffer to decode.\n    conversion_gain : float\n        Signal intensity increase per photon.\n    zero_level : int\n        Signal level when no photons are recorded.\n    encoded_dtype : numpy.typing.DtypeLike\n        NumPy dtype of encoded data.\n    decoded_dtype : numpy.typing.DtypeLike\n        NumPy dtype for decoded output.\n\n    Returns\n    -------\n    np.ndarray\n        Decoded array with original value scale.\n    \"\"\"\n    lookup_table = make_anscombe_lookup(\n        conversion_gain,\n        output_type=encoded_dtype,\n        zero_level=zero_level,\n    )\n    inverse_table = make_inverse_lookup(lookup_table, output_type=decoded_dtype)\n    decoded = np.frombuffer(buf, dtype=encoded_dtype)\n    return lookup(decoded, inverse_table).astype(decoded_dtype)\n</code></pre>"},{"location":"api/codec/#lookup-table-functions","title":"Lookup Table Functions","text":""},{"location":"api/codec/#make_anscombe_lookup","title":"make_anscombe_lookup","text":""},{"location":"api/codec/#anscombe_transform.codec.make_anscombe_lookup","title":"<code>make_anscombe_lookup(conversion_gain, input_max=32767, zero_level=0, beta=0.5, output_type='uint8')</code>","text":"<p>Compute the Anscombe lookup table.</p> <p>The lookup converts a linear grayscale image into a uniform variance image by applying the Anscombe variance-stabilizing transformation.</p> <p>Parameters:</p> Name Type Description Default <code>conversion_gain</code> <code>float</code> <p>Estimated signal intensity increase per quantum (e.g. photon).</p> required <code>input_max</code> <code>int</code> <p>The maximum value in the input data, by default 0x7FFF (32767).</p> <code>32767</code> <code>zero_level</code> <code>int</code> <p>Signal level when no photons are recorded, by default 0.</p> <code>0</code> <code>beta</code> <code>float</code> <p>The grayscale quantization step expressed in units of noise std dev, by default 0.5.</p> <code>0.5</code> <code>output_type</code> <code>str</code> <p>NumPy dtype string for output array, by default \"uint8\".</p> <code>'uint8'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Lookup table array for Anscombe transformation.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def make_anscombe_lookup(\n    conversion_gain: float,\n    input_max: int = 0x7FFF,\n    zero_level: int = 0,\n    beta: float = 0.5,\n    output_type: str = \"uint8\",\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute the Anscombe lookup table.\n\n    The lookup converts a linear grayscale image into a uniform variance image\n    by applying the Anscombe variance-stabilizing transformation.\n\n    Parameters\n    ----------\n    conversion_gain : float\n        Estimated signal intensity increase per quantum (e.g. photon).\n    input_max : int, optional\n        The maximum value in the input data, by default 0x7FFF (32767).\n    zero_level : int, optional\n        Signal level when no photons are recorded, by default 0.\n    beta : float, optional\n        The grayscale quantization step expressed in units of noise std dev, by default 0.5.\n    output_type : str, optional\n        NumPy dtype string for output array, by default \"uint8\".\n\n    Returns\n    -------\n    np.ndarray\n        Lookup table array for Anscombe transformation.\n    \"\"\"\n    xx = (np.r_[: input_max + 1] - zero_level) / conversion_gain  # input expressed in photon rates\n    zero_slope = 1 / beta / np.sqrt(3 / 8)  # slope for negative values\n    offset = zero_level * zero_slope / conversion_gain\n    lookup_table = np.round(\n        offset\n        + (xx &lt; 0) * (xx * zero_slope)\n        + (xx &gt;= 0) * (2.0 / beta * (np.sqrt(np.maximum(0, xx) + 3 / 8) - np.sqrt(3 / 8)))\n    )\n    lookup = lookup_table.astype(output_type)\n    assert np.diff(lookup_table).min() &gt;= 0, \"non-monotonic lookup generated\"\n    return lookup\n</code></pre>"},{"location":"api/codec/#make_inverse_lookup","title":"make_inverse_lookup","text":""},{"location":"api/codec/#anscombe_transform.codec.make_inverse_lookup","title":"<code>make_inverse_lookup(lookup_table, output_type='int16')</code>","text":"<p>Compute the inverse lookup table for a monotonic forward lookup table.</p> <p>Parameters:</p> Name Type Description Default <code>lookup_table</code> <code>ndarray</code> <p>Monotonic forward lookup table.</p> required <code>output_type</code> <code>str</code> <p>NumPy dtype string for output array, by default \"int16\".</p> <code>'int16'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Inverse lookup table that maps encoded values back to original values.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def make_inverse_lookup(lookup_table: np.ndarray, output_type=\"int16\") -&gt; np.ndarray:\n    \"\"\"\n    Compute the inverse lookup table for a monotonic forward lookup table.\n\n    Parameters\n    ----------\n    lookup_table : np.ndarray\n        Monotonic forward lookup table.\n    output_type : str, optional\n        NumPy dtype string for output array, by default \"int16\".\n\n    Returns\n    -------\n    np.ndarray\n        Inverse lookup table that maps encoded values back to original values.\n    \"\"\"\n    _, inv1 = np.unique(lookup_table, return_index=True)  # first entry\n    _, inv2 = np.unique(lookup_table[::-1], return_index=True)  # last entry\n    inverse = (inv1 + lookup_table.size - 1 - inv2) / 2\n    return inverse.astype(output_type)\n</code></pre>"},{"location":"api/codec/#lookup","title":"lookup","text":""},{"location":"api/codec/#anscombe_transform.codec.lookup","title":"<code>lookup(movie, lookup_table)</code>","text":"<p>Apply lookup table to movie with boundary clamping.</p> <p>Parameters:</p> Name Type Description Default <code>movie</code> <code>ndarray</code> <p>Input array to transform.</p> required <code>lookup_table</code> <code>ndarray</code> <p>Lookup table for transformation.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Transformed array with values from lookup table.</p> Source code in <code>src/anscombe_transform/codec.py</code> <pre><code>def lookup(movie: np.ndarray, lookup_table: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Apply lookup table to movie with boundary clamping.\n\n    Parameters\n    ----------\n    movie : np.ndarray\n        Input array to transform.\n    lookup_table : np.ndarray\n        Lookup table for transformation.\n\n    Returns\n    -------\n    np.ndarray\n        Transformed array with values from lookup table.\n    \"\"\"\n    return lookup_table[np.maximum(0, np.minimum(movie, lookup_table.size - 1))]\n</code></pre>"},{"location":"api/estimate/","title":"Estimation API Reference","text":"<p>This page documents the parameter estimation functions.</p>"},{"location":"api/estimate/#compute_sensitivity","title":"compute_sensitivity","text":""},{"location":"api/estimate/#anscombe_transform.estimate.compute_sensitivity","title":"<code>compute_sensitivity(movie, count_weight_gamma=0.2)</code>","text":"<p>Calculate photon sensitivity and zero level from temporal variance analysis.</p> <p>This function estimates camera parameters by fitting the noise transfer function from temporal variance. It uses HuberRegressor to robustly fit the relationship between mean signal and variance.</p> <p>Parameters:</p> Name Type Description Default <code>movie</code> <code>ndarray</code> <p>A movie in the format (time, height, width).</p> required <code>count_weight_gamma</code> <code>float</code> <p>Weighting exponent for pixel counts in regression, by default 0.2. - 0.0: weigh each intensity level equally - 1.0: weigh each intensity in proportion to pixel counts</p> <code>0.2</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with the following keys:</p> <ul> <li>'model' : HuberRegressor     The fitted regression model.</li> <li>'counts' : np.ndarray     Pixel counts per intensity bin.</li> <li>'min_intensity' : int     Minimum intensity value used in fitting.</li> <li>'max_intensity' : int     Maximum intensity value used in fitting.</li> <li>'variance' : np.ndarray     Computed variance at each intensity level.</li> <li>'sensitivity' : float     Estimated photon sensitivity (ADU per photon).</li> <li>'zero_level' : float     Estimated baseline signal level with no photons.</li> </ul> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If movie is not 3-dimensional or if insufficient intensity range is present.</p> Source code in <code>src/anscombe_transform/estimate.py</code> <pre><code>def compute_sensitivity(movie: np.array, count_weight_gamma: float = 0.2) -&gt; dict:\n    \"\"\"\n    Calculate photon sensitivity and zero level from temporal variance analysis.\n\n    This function estimates camera parameters by fitting the noise transfer function\n    from temporal variance. It uses HuberRegressor to robustly fit the relationship\n    between mean signal and variance.\n\n    Parameters\n    ----------\n    movie : np.ndarray\n        A movie in the format (time, height, width).\n    count_weight_gamma : float, optional\n        Weighting exponent for pixel counts in regression, by default 0.2.\n        - 0.0: weigh each intensity level equally\n        - 1.0: weigh each intensity in proportion to pixel counts\n\n    Returns\n    -------\n    dict\n        Dictionary with the following keys:\n\n        - 'model' : HuberRegressor\n            The fitted regression model.\n        - 'counts' : np.ndarray\n            Pixel counts per intensity bin.\n        - 'min_intensity' : int\n            Minimum intensity value used in fitting.\n        - 'max_intensity' : int\n            Maximum intensity value used in fitting.\n        - 'variance' : np.ndarray\n            Computed variance at each intensity level.\n        - 'sensitivity' : float\n            Estimated photon sensitivity (ADU per photon).\n        - 'zero_level' : float\n            Estimated baseline signal level with no photons.\n\n    Raises\n    ------\n    AssertionError\n        If movie is not 3-dimensional or if insufficient intensity range is present.\n    \"\"\"\n    assert movie.ndim == 3, (\n        f\"Thee dimensions (Time x Height x Width) of grayscale movie expected, got {movie.ndim} dimensions\"\n    )\n\n    # assume that negative values are due to noise\n    movie = np.maximum(0, movie.astype(np.int32, copy=False))\n    intensity = (movie[:-1, :, :] + movie[1:, :, :] + 1) // 2\n    difference = movie[:-1, :, :].astype(np.float32) - movie[1:, :, :]\n\n    select = intensity &gt; 0  # discard non-positive values\n    intensity = intensity[select]\n    difference = difference[select]\n\n    counts = np.bincount(intensity.flatten())\n    bins = _longest_run(\n        counts &gt; 0.01 * counts.mean()\n    )  # consider only bins with at least 1% of mean counts\n    bins = slice(max(bins.stop * 3 // 100, bins.start), bins.stop)\n    assert bins.stop - bins.start &gt; 100, (\n        \"The image does not have a sufficient range of intensities to compute the noise transfer function.\"\n    )\n\n    counts = counts[bins]\n    idx = (intensity &gt;= bins.start) &amp; (intensity &lt; bins.stop)\n    variance = (\n        np.bincount(\n            intensity[idx] - bins.start,\n            weights=(difference[idx] ** 2) / 2,\n        )\n        / counts\n    )\n    model = Regressor()\n    model.fit(np.c_[bins], variance, counts**count_weight_gamma)\n    sensitivity = model.coef_[0]\n    zero_level = -model.intercept_ / model.coef_[0]\n\n    return dict(\n        model=model,\n        counts=counts,\n        min_intensity=bins.start,\n        max_intensity=bins.stop,\n        variance=variance,\n        sensitivity=sensitivity,\n        zero_level=zero_level,\n    )\n</code></pre>"},{"location":"examples/workbook/","title":"Complete Workflow Example","text":"<p>This page provides a complete end-to-end example of using the Anscombe Transform codec.</p> <p>For an interactive version, see the Jupyter notebook in the repository.</p>"},{"location":"examples/workbook/#overview","title":"Overview","text":"<p>This example demonstrates:</p> <ol> <li>Loading sample photon-limited data</li> <li>Estimating codec parameters</li> <li>Compressing data with Zarr V3</li> <li>Validating reconstruction quality</li> <li>Measuring compression ratios</li> </ol>"},{"location":"examples/workbook/#setup","title":"Setup","text":"<pre><code>import numpy as np\nimport zarr\nfrom anscombe_transform import AnscombeTransformV3, compute_sensitivity\nimport matplotlib.pyplot as plt\n</code></pre>"},{"location":"examples/workbook/#generate-sample-data","title":"Generate Sample Data","text":"<p>First, let's create synthetic data that mimics photon-limited imaging:</p> <pre><code># Parameters for synthetic data\nn_frames = 100\nheight, width = 512, 512\nmean_photons = 50  # Average photons per pixel\nzero_level = 100   # Camera baseline\nconversion_gain = 2.5  # ADU per photon\n\n# Generate Poisson-distributed photon counts\nphoton_counts = np.random.poisson(lam=mean_photons, size=(n_frames, height, width))\n\n# Convert to camera signal (ADU)\ncamera_signal = (photon_counts * conversion_gain + zero_level).astype('int16')\n\nprint(f\"Data shape: {camera_signal.shape}\")\nprint(f\"Data range: [{camera_signal.min()}, {camera_signal.max()}]\")\nprint(f\"Data dtype: {camera_signal.dtype}\")\n</code></pre>"},{"location":"examples/workbook/#estimate-parameters","title":"Estimate Parameters","text":"<p>Now estimate the codec parameters from the data:</p> <pre><code># Estimate parameters from the movie\nresult = compute_sensitivity(camera_signal)\n\nestimated_gain = result['sensitivity']\nestimated_zero = result['zero_level']\n\nprint(f\"\\nTrue parameters:\")\nprint(f\"  Conversion gain: {conversion_gain:.3f} ADU/photon\")\nprint(f\"  Zero level: {zero_level:.1f} ADU\")\n\nprint(f\"\\nEstimated parameters:\")\nprint(f\"  Conversion gain: {estimated_gain:.3f} ADU/photon\")\nprint(f\"  Zero level: {estimated_zero:.1f} ADU\")\n\nprint(f\"\\nEstimation error:\")\nprint(f\"  Gain error: {abs(estimated_gain - conversion_gain):.3f} ADU/photon\")\nprint(f\"  Zero level error: {abs(estimated_zero - zero_level):.1f} ADU\")\n</code></pre>"},{"location":"examples/workbook/#visualize-noise-model","title":"Visualize Noise Model","text":"<p>Plot the noise model fit:</p> <pre><code># Compute mean and variance\nmean_signal = np.mean(camera_signal, axis=0)\nvariance = np.var(camera_signal, axis=0)\n\n# Create scatter plot\nplt.figure(figsize=(10, 6))\nplt.scatter(mean_signal.ravel()[::100], variance.ravel()[::100],\n            alpha=0.5, s=1, label='Data')\n\n# Plot fitted line\nmean_range = np.array([mean_signal.min(), mean_signal.max()])\nvariance_fit = estimated_gain * (mean_range - estimated_zero)\nplt.plot(mean_range, variance_fit, 'r-', linewidth=2,\n         label=f'Fit: var = {estimated_gain:.2f} * (mean - {estimated_zero:.1f})')\n\nplt.xlabel('Mean Signal (ADU)')\nplt.ylabel('Variance (ADU\u00b2)')\nplt.title('Noise Transfer Function')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"examples/workbook/#compress-with-anscombe-codec","title":"Compress with Anscombe Codec","text":"<p>Create a Zarr array with the codec:</p> <pre><code># Create codec with estimated parameters\ncodec = AnscombeTransformV3(\n    zero_level=estimated_zero,\n    conversion_gain=estimated_gain,\n    encoded_dtype='uint8'\n)\n\n# Create Zarr V3 array\nstore = zarr.storage.MemoryStore()\ncompressed_array = zarr.create(\n    store=store,\n    shape=camera_signal.shape,\n    chunks=(10, 512, 512),\n    dtype='int16',\n    filters=[codec],\n    compressor={'id': 'blosc', 'cname': 'zstd', 'clevel': 5},\n    zarr_format=3\n)\n\n# Write data\ncompressed_array[:] = camera_signal\n\nprint(f\"Compression complete!\")\n</code></pre>"},{"location":"examples/workbook/#validate-reconstruction","title":"Validate Reconstruction","text":"<p>Check the quality of reconstruction:</p> <pre><code># Read back compressed data\nreconstructed = compressed_array[:]\n\n# Compute reconstruction error\nerror = camera_signal - reconstructed\nabs_error = np.abs(error)\n\nprint(f\"\\nReconstruction Quality:\")\nprint(f\"  Max absolute error: {abs_error.max():.2f} ADU\")\nprint(f\"  Mean absolute error: {abs_error.mean():.2f} ADU\")\nprint(f\"  RMS error: {np.sqrt(np.mean(error**2)):.2f} ADU\")\nprint(f\"  Expected noise (1 photon): {estimated_gain:.2f} ADU\")\nprint(f\"  Error as fraction of noise: {abs_error.mean() / estimated_gain:.2f}\")\n\n# Visualize error distribution\nplt.figure(figsize=(12, 4))\n\nplt.subplot(131)\nplt.imshow(camera_signal[0], cmap='gray', vmin=0, vmax=500)\nplt.title('Original Frame')\nplt.colorbar(label='ADU')\n\nplt.subplot(132)\nplt.imshow(reconstructed[0], cmap='gray', vmin=0, vmax=500)\nplt.title('Reconstructed Frame')\nplt.colorbar(label='ADU')\n\nplt.subplot(133)\nplt.imshow(error[0], cmap='RdBu_r', vmin=-10, vmax=10)\nplt.title('Error (Original - Reconstructed)')\nplt.colorbar(label='ADU')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"examples/workbook/#measure-compression-ratio","title":"Measure Compression Ratio","text":"<p>Calculate the compression achieved:</p> <pre><code># Original size\noriginal_size = camera_signal.nbytes\n\n# Compressed size (estimate from store)\ncompressed_size = sum(len(v) for v in store.values())\n\ncompression_ratio = original_size / compressed_size\n\nprint(f\"\\nCompression Statistics:\")\nprint(f\"  Original size: {original_size / 1024**2:.2f} MB\")\nprint(f\"  Compressed size: {compressed_size / 1024**2:.2f} MB\")\nprint(f\"  Compression ratio: {compression_ratio:.2f}x\")\nprint(f\"  Space saved: {(1 - 1/compression_ratio) * 100:.1f}%\")\n</code></pre>"},{"location":"examples/workbook/#compare-different-compressors","title":"Compare Different Compressors","text":"<p>Test various compressor configurations:</p> <pre><code>compressors = [\n    {'name': 'Blosc+Zstd', 'config': {'id': 'blosc', 'cname': 'zstd', 'clevel': 5}},\n    {'name': 'Blosc+LZ4', 'config': {'id': 'blosc', 'cname': 'lz4', 'clevel': 3}},\n    {'name': 'Blosc+Zlib', 'config': {'id': 'blosc', 'cname': 'zlib', 'clevel': 9}},\n]\n\nresults = []\n\nfor comp in compressors:\n    store = zarr.storage.MemoryStore()\n    arr = zarr.create(\n        store=store,\n        shape=camera_signal.shape,\n        chunks=(10, 512, 512),\n        dtype='int16',\n        filters=[codec],\n        compressor=comp['config'],\n        zarr_format=3\n    )\n    arr[:] = camera_signal\n\n    compressed_size = sum(len(v) for v in store.values())\n    ratio = original_size / compressed_size\n\n    results.append({\n        'name': comp['name'],\n        'size_mb': compressed_size / 1024**2,\n        'ratio': ratio\n    })\n\n    print(f\"{comp['name']:15s}: {ratio:.2f}x compression, {compressed_size / 1024**2:.2f} MB\")\n\n# Plot comparison\nplt.figure(figsize=(10, 5))\nnames = [r['name'] for r in results]\nratios = [r['ratio'] for r in results]\nplt.bar(names, ratios)\nplt.ylabel('Compression Ratio')\nplt.title('Compression Performance by Algorithm')\nplt.grid(axis='y', alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"examples/workbook/#summary","title":"Summary","text":"<p>This example demonstrated:</p> <ul> <li>\u2705 Parameter estimation with ~1% accuracy</li> <li>\u2705 Reconstruction error below 1 photon equivalent</li> <li>\u2705 5-8x compression ratios</li> <li>\u2705 Successful integration with Zarr V3</li> </ul>"},{"location":"examples/workbook/#next-steps","title":"Next Steps","text":"<ul> <li>Try with your own data</li> <li>Experiment with different <code>beta</code> values</li> <li>Compare with other compression algorithms</li> <li>Use with remote storage backends</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#from-pypi","title":"From PyPI","text":"<p>The recommended way to install the Anscombe Transform codec is via pip:</p> <pre><code>pip install anscombe-transform\n</code></pre>"},{"location":"getting-started/installation/#from-source","title":"From Source","text":"<p>For development or to get the latest unreleased features:</p> <pre><code>git clone https://github.com/datajoint/anscombe-transform.git\ncd anscombe-transform\npip install -e .\n</code></pre>"},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python &gt;= 3.11</li> <li>zarr &gt;= 3.1.2</li> <li>scikit-learn</li> <li>numpy</li> </ul>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>For running tests and examples:</p> <pre><code>pip install anscombe-transform[test]\n</code></pre> <p>This includes: - pytest - pytest-cov - nbmake (for testing notebooks) - scipy - imageio - matplotlib</p>"},{"location":"getting-started/installation/#verifying-installation","title":"Verifying Installation","text":"<p>You can verify the installation by running:</p> <pre><code>import anscombe_transform\nprint(anscombe_transform.__version__)\n</code></pre> <p>Or run the test suite:</p> <pre><code>pytest tests/\n</code></pre>"},{"location":"getting-started/installation/#development-installation","title":"Development Installation","text":"<p>For contributors using Hatch:</p> <pre><code># Install hatch\npip install hatch\n\n# Run tests across all environments\nhatch run test:pytest tests/\n\n# Run tests for a specific Python/NumPy version\nhatch run test.py3.11-2.2:pytest tests/\n\n# Enter a development shell\nhatch shell\n</code></pre> <p>See the Contributing Guide for more details on development setup.</p>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>This guide will help you get started with the Anscombe Transform codec for compressing photon-limited movies.</p>"},{"location":"getting-started/quick-start/#basic-usage-with-zarr-v3","title":"Basic Usage with Zarr V3","text":"<pre><code>import zarr\nimport numpy as np\nfrom anscombe_transform import AnscombeTransformV3\n\n# Generate sample data with Poisson noise\n# Simulating photon-limited imaging data\ndata = np.random.poisson(lam=50, size=(100, 512, 512)).astype('int16')\n\n# Create a Zarr array with the Anscombe codec\nstore = zarr.storage.MemoryStore()\narr = zarr.create(\n    store=store,\n    shape=data.shape,\n    chunks=(10, 512, 512),\n    dtype='int16',\n    filters=[AnscombeTransformV3(zero_level=100, conversion_gain=2.5)],\n    zarr_format=3\n)\n\n# Write data\narr[:] = data\n\n# Read data back\nrecovered = arr[:]\n\n# Verify roundtrip accuracy\nprint(f\"Max difference: {np.abs(data - recovered).max()}\")\n</code></pre>"},{"location":"getting-started/quick-start/#using-with-zarr-v2","title":"Using with Zarr V2","text":"<pre><code>from anscombe_transform import AnscombeTransformV2\nimport zarr\n\n# Create array with V2 codec\narr = zarr.open_array(\n    'data.zarr',\n    mode='w',\n    shape=(100, 512, 512),\n    chunks=(10, 512, 512),\n    dtype='int16',\n    compressor=AnscombeTransformV2(zero_level=100, conversion_gain=2.5)\n)\n\n# Write and read data\narr[:] = data\nrecovered = arr[:]\n</code></pre>"},{"location":"getting-started/quick-start/#estimating-parameters-from-data","title":"Estimating Parameters from Data","text":"<p>If you don't know the <code>zero_level</code> and <code>conversion_gain</code> parameters, you can estimate them from your data:</p> <pre><code>from anscombe_transform import compute_sensitivity\nimport numpy as np\n\n# Load your movie data as (time, height, width)\nmovie = np.random.poisson(lam=50, size=(100, 512, 512))\n\n# Estimate parameters\nresult = compute_sensitivity(movie)\n\nprint(f\"Estimated conversion gain: {result['sensitivity']:.3f}\")\nprint(f\"Estimated zero level: {result['zero_level']:.3f}\")\n\n# Use estimated parameters in codec\ncodec = AnscombeTransformV3(\n    zero_level=result['zero_level'],\n    conversion_gain=result['sensitivity']\n)\n</code></pre>"},{"location":"getting-started/quick-start/#combining-with-other-compressors","title":"Combining with Other Compressors","text":"<p>The Anscombe codec is typically used as a filter before compression:</p> <pre><code>import zarr\nfrom numcodecs import Blosc\nfrom anscombe_transform import AnscombeTransformV3\n\n# For Zarr V3, use filters + codecs\narr = zarr.create(\n    shape=(100, 512, 512),\n    chunks=(10, 512, 512),\n    dtype='int16',\n    filters=[AnscombeTransformV3(zero_level=100, conversion_gain=2.5)],\n    compressor={'id': 'blosc', 'cname': 'zstd', 'clevel': 5},\n    zarr_format=3\n)\n</code></pre>"},{"location":"getting-started/quick-start/#key-parameters","title":"Key Parameters","text":"<ul> <li><code>zero_level</code>: The signal value when no photons are detected. This is the baseline offset in your camera sensor.</li> <li><code>conversion_gain</code> (also called <code>photon_sensitivity</code>): How many signal units correspond to one photon. For example, if your camera reports 2.5 ADU per photon, use <code>conversion_gain=2.5</code>.</li> <li><code>encoded_dtype</code>: The data type for encoded values (default: <code>uint8</code>). Use <code>uint8</code> for maximum compression.</li> <li><code>decoded_dtype</code>: The data type for decoded values (default: inferred from data).</li> </ul>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<ul> <li>Learn more in the User Guide</li> <li>See Parameter Estimation for details on computing parameters</li> <li>Check out the full Workbook Example</li> <li>Explore the API Reference</li> </ul>"},{"location":"user-guide/overview/","title":"Overview","text":""},{"location":"user-guide/overview/#the-anscombe-transform","title":"The Anscombe Transform","text":"<p>The Anscombe Transform is a variance-stabilizing transformation specifically designed for data with Poisson noise. In photon-limited imaging, the noise variance equals the signal mean (characteristic of Poisson statistics), which makes compression difficult because different intensity levels have different noise characteristics.</p>"},{"location":"user-guide/overview/#the-problem","title":"The Problem","text":"<p>In photon-limited data: - Low intensity regions have low noise variance - High intensity regions have high noise variance - This heteroscedastic noise makes efficient compression challenging</p>"},{"location":"user-guide/overview/#the-solution","title":"The Solution","text":"<p>The Anscombe Transform applies a square-root-like transformation that: 1. Equalizes noise variance across all intensity levels 2. Reduces the number of unique grayscale values needed 3. Improves compressibility without losing signal accuracy</p> <p>Mathematically, the transform is:</p> <pre><code>f(x) = 2 * sqrt(x + 3/8)\n</code></pre> <p>For our codec, we adapt this to account for camera parameters:</p> <pre><code>encoded = quantize(2 * sqrt((data - zero_level) / conversion_gain + 3/8))\n</code></pre>"},{"location":"user-guide/overview/#codec-architecture","title":"Codec Architecture","text":"<p>The codec is implemented in two versions to support both Zarr V2 and V3:</p>"},{"location":"user-guide/overview/#zarr-v2-anscombetransformv2","title":"Zarr V2: <code>AnscombeTransformV2</code>","text":"<ul> <li>Implements the <code>numcodecs.Codec</code> interface</li> <li>Used as a compressor in Zarr V2 arrays</li> <li>Registered with ID <code>\"anscombe-v1\"</code></li> </ul>"},{"location":"user-guide/overview/#zarr-v3-anscombetransformv3","title":"Zarr V3: <code>AnscombeTransformV3</code>","text":"<ul> <li>Implements the <code>ArrayArrayCodec</code> interface</li> <li>Used as a filter before compression in Zarr V3 arrays</li> <li>Registered with the same ID <code>\"anscombe-v1\"</code></li> </ul> <p>Both share the same core <code>encode()</code> and <code>decode()</code> functions, ensuring consistent behavior.</p>"},{"location":"user-guide/overview/#how-it-works","title":"How It Works","text":""},{"location":"user-guide/overview/#encoding-pipeline","title":"Encoding Pipeline","text":"<ol> <li>Normalize: Convert raw data to photon counts using <code>conversion_gain</code> and <code>zero_level</code></li> <li>Transform: Apply the Anscombe Transform to stabilize variance</li> <li>Quantize: Discretize the transformed values to <code>encoded_dtype</code> (typically <code>uint8</code>)</li> <li>Compress: Apply additional compression (e.g., Blosc, Zstd)</li> </ol>"},{"location":"user-guide/overview/#decoding-pipeline","title":"Decoding Pipeline","text":"<ol> <li>Decompress: Uncompress the data</li> <li>Lookup: Apply inverse transform via lookup table</li> <li>Denormalize: Convert back to original units using <code>conversion_gain</code> and <code>zero_level</code></li> </ol>"},{"location":"user-guide/overview/#lookup-tables","title":"Lookup Tables","text":"<p>The codec uses pre-computed lookup tables for efficiency: - Forward lookup: Maps input values to transformed values - Inverse lookup: Maps transformed values back to original values</p> <p>These tables are computed once during codec initialization and reused for all encode/decode operations.</p>"},{"location":"user-guide/overview/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"user-guide/overview/#compression-ratios","title":"Compression Ratios","text":"<p>Typical compression ratios (Anscombe + Blosc/Zstd): - 4-8x for typical multiphoton microscopy data - 6-10x for astronomy data - 3-6x for radiography data</p> <p>The exact ratio depends on: - Signal-to-noise ratio of the data - Spatial correlation in the images - Choice of secondary compressor</p>"},{"location":"user-guide/overview/#speed","title":"Speed","text":"<p>The codec is designed for speed: - Encoding: ~500-1000 MB/s (single-threaded) - Decoding: ~800-1500 MB/s (single-threaded) - Scales well with chunk-based parallel processing</p>"},{"location":"user-guide/overview/#accuracy","title":"Accuracy","text":"<p>The codec is designed to be nearly lossless for photon-limited data: - Typical error: &lt; 1 photon per pixel - Error scales with <code>conversion_gain</code> and quantization (<code>beta</code> parameter) - For well-chosen parameters, reconstruction error is below the noise floor</p>"},{"location":"user-guide/overview/#when-to-use-this-codec","title":"When to Use This Codec","text":""},{"location":"user-guide/overview/#good-use-cases","title":"Good Use Cases \u2705","text":"<ul> <li>Multiphoton microscopy movies</li> <li>Astronomy images with photon counting detectors</li> <li>Radiography/X-ray imaging</li> <li>Any data with Poisson noise where signal \u2248 variance</li> <li>Data where you can estimate or know <code>conversion_gain</code> and <code>zero_level</code></li> </ul>"},{"location":"user-guide/overview/#not-recommended","title":"Not Recommended \u274c","text":"<ul> <li>Data without Poisson noise (e.g., pre-processed images)</li> <li>Data where camera parameters are unknown and can't be estimated</li> <li>Data with very high dynamic range (&gt; 16-bit)</li> <li>Data that has already been normalized or transformed</li> </ul>"},{"location":"user-guide/overview/#next-steps","title":"Next Steps","text":"<ul> <li>Parameter Estimation Guide</li> <li>Zarr V2 Integration</li> <li>Zarr V3 Integration</li> </ul>"},{"location":"user-guide/parameter-estimation/","title":"Parameter Estimation","text":"<p>To use the Anscombe Transform codec effectively, you need two key parameters:</p> <ol> <li><code>zero_level</code>: The baseline signal value when no photons are detected</li> <li><code>conversion_gain</code> (also called <code>photon_sensitivity</code>): The conversion factor from signal units to photon counts</li> </ol> <p>This guide explains how to estimate these parameters from your data.</p>"},{"location":"user-guide/parameter-estimation/#the-compute_sensitivity-function","title":"The <code>compute_sensitivity()</code> Function","text":"<p>The codec provides a built-in parameter estimation function:</p> <pre><code>from anscombe_transform import compute_sensitivity\nimport numpy as np\n\n# Load your movie data as (time, height, width)\nmovie = load_my_movie()  # Shape: (n_frames, height, width)\n\n# Estimate parameters\nresult = compute_sensitivity(movie)\n\nprint(f\"Conversion gain: {result['sensitivity']:.3f}\")\nprint(f\"Zero level: {result['zero_level']:.3f}\")\n</code></pre>"},{"location":"user-guide/parameter-estimation/#input-requirements","title":"Input Requirements","text":"<p>The <code>compute_sensitivity()</code> function expects: - Shape: <code>(time, height, width)</code> - temporal axis must be first - Data type: Integer or float - Minimum frames: At least 10-20 frames for reliable estimation - Static scene: Works best when the scene doesn't change much over time</p>"},{"location":"user-guide/parameter-estimation/#how-it-works","title":"How It Works","text":"<p>The function uses the noise transfer function approach:</p> <ol> <li>Compute temporal variance: Calculate pixel-wise variance across time</li> <li>Compute temporal mean: Calculate pixel-wise mean across time</li> <li>Fit noise model: Use HuberRegressor to fit <code>variance = slope * mean + intercept</code></li> </ol> <p>For Poisson noise: <code>variance = conversion_gain * (mean - zero_level)</code></p> <p>Therefore: - <code>conversion_gain = slope</code> - <code>zero_level = -intercept / slope</code></p>"},{"location":"user-guide/parameter-estimation/#return-value","title":"Return Value","text":"<p>The function returns a dictionary with:</p> <pre><code>{\n    'sensitivity': float,      # The conversion gain (photons per signal unit)\n    'zero_level': float,       # The baseline signal level\n    'variance': ndarray,       # Computed pixel-wise variance\n    'model': HuberRegressor    # The fitted regression model\n}\n</code></pre>"},{"location":"user-guide/parameter-estimation/#manual-parameter-estimation","title":"Manual Parameter Estimation","text":"<p>If you know your camera specifications, you can compute the parameters manually:</p>"},{"location":"user-guide/parameter-estimation/#zero-level","title":"Zero Level","text":"<p>The zero level is typically: - Dark current: The signal level with the shutter closed - Bias level: The electronic offset added to prevent negative values</p> <p>To measure: 1. Capture several frames with no light (shutter closed or lens cap on) 2. Compute the median value across all pixels and frames</p> <pre><code>dark_frames = capture_dark_frames(n=20)\nzero_level = np.median(dark_frames)\n</code></pre>"},{"location":"user-guide/parameter-estimation/#conversion-gain","title":"Conversion Gain","text":"<p>The conversion gain depends on your camera's specifications:</p> <pre><code># If you know electrons per ADU:\nelectrons_per_adu = 2.5  # From camera spec sheet\nquantum_efficiency = 0.9  # Photons to electrons conversion\n\nconversion_gain = electrons_per_adu / quantum_efficiency\n</code></pre> <p>Or measure from a uniform illumination:</p> <pre><code># Capture frames of uniform illumination\nuniform_frames = capture_uniform_frames(n=100)\n\n# Compute mean and variance for each pixel\nmean = np.mean(uniform_frames, axis=0)\nvariance = np.var(uniform_frames, axis=0)\n\n# For Poisson noise: variance = gain * (mean - zero)\n# Fit a line through the origin after subtracting zero level\nconversion_gain = np.median(variance / (mean - zero_level))\n</code></pre>"},{"location":"user-guide/parameter-estimation/#validation","title":"Validation","text":"<p>After estimating parameters, validate them:</p> <pre><code>from anscombe_transform import AnscombeTransformV3\n\n# Create codec with estimated parameters\ncodec = AnscombeTransformV3(\n    zero_level=result['zero_level'],\n    conversion_gain=result['sensitivity']\n)\n\n# Test on a sample frame\nframe = movie[0]\nencoded = codec.encode(frame)\ndecoded = codec.decode(encoded)\n\n# Check reconstruction error\nerror = np.abs(frame - decoded)\nmax_error = np.max(error)\nmean_error = np.mean(error)\n\nprint(f\"Max error: {max_error:.2f} ADU\")\nprint(f\"Mean error: {mean_error:.2f} ADU\")\nprint(f\"Expected noise (1 photon): {result['sensitivity']:.2f} ADU\")\n\n# Error should be less than ~1 photon equivalent\nassert max_error &lt; 2 * result['sensitivity']\n</code></pre>"},{"location":"user-guide/parameter-estimation/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/parameter-estimation/#data-collection","title":"Data Collection","text":"<ol> <li>Use multiple frames: 20+ frames for reliable statistics</li> <li>Avoid motion: Use static scenes or stabilized video</li> <li>Cover dynamic range: Include both bright and dark regions</li> <li>Use raw data: Don't use pre-processed or normalized data</li> </ol>"},{"location":"user-guide/parameter-estimation/#parameter-refinement","title":"Parameter Refinement","text":"<ol> <li>Check fit quality: Inspect <code>result['model'].score()</code> (R\u00b2 should be &gt; 0.95)</li> <li>Visualize fit: Plot variance vs. mean to verify linear relationship</li> <li>Test reconstruction: Verify that encoding/decoding preserves data quality</li> </ol>"},{"location":"user-guide/parameter-estimation/#common-issues","title":"Common Issues","text":"<p>Negative zero level: Usually indicates pre-processed data or incorrect bias subtraction. Check if your data has been normalized.</p> <p>Very high conversion gain (&gt; 10): May indicate the data is already in photon units or has been scaled.</p> <p>Poor R\u00b2 score (&lt; 0.9): Could mean: - Too much motion in the scene - Non-Poisson noise dominates (e.g., readout noise) - Not enough temporal variation</p>"},{"location":"user-guide/parameter-estimation/#example-workflow","title":"Example Workflow","text":"<pre><code>import numpy as np\nfrom anscombe_transform import compute_sensitivity, AnscombeTransformV3\nimport zarr\n\n# 1. Load temporal data\nmovie = load_movie()  # Shape: (100, 512, 512)\n\n# 2. Estimate parameters\nparams = compute_sensitivity(movie)\nprint(f\"Estimated parameters:\")\nprint(f\"  Conversion gain: {params['sensitivity']:.3f} ADU/photon\")\nprint(f\"  Zero level: {params['zero_level']:.1f} ADU\")\n\n# 3. Validate fit quality\nr2_score = params['model'].score(\n    params['variance'].ravel().reshape(-1, 1),\n    np.mean(movie, axis=0).ravel()\n)\nprint(f\"  Fit quality (R\u00b2): {r2_score:.3f}\")\n\n# 4. Create codec with estimated parameters\ncodec = AnscombeTransformV3(\n    zero_level=params['zero_level'],\n    conversion_gain=params['sensitivity']\n)\n\n# 5. Create Zarr array\narr = zarr.create(\n    shape=movie.shape,\n    chunks=(10, 512, 512),\n    dtype='int16',\n    filters=[codec],\n    zarr_format=3\n)\n\n# 6. Compress data\narr[:] = movie\nprint(f\"Compression successful!\")\n</code></pre>"},{"location":"user-guide/parameter-estimation/#next-steps","title":"Next Steps","text":"<ul> <li>Zarr V2 Integration</li> <li>Zarr V3 Integration</li> <li>API Reference: estimate module</li> </ul>"},{"location":"user-guide/zarr-v2/","title":"Zarr V2 Integration","text":"<p>This guide covers using the Anscombe Transform codec with Zarr V2.</p>"},{"location":"user-guide/zarr-v2/#basic-usage","title":"Basic Usage","text":"<pre><code>import zarr\nimport numpy as np\nfrom anscombe_transform import AnscombeTransformV2\n\n# Create data\ndata = np.random.poisson(lam=50, size=(100, 512, 512)).astype('int16')\n\n# Create Zarr V2 array with Anscombe codec as compressor\narr = zarr.open_array(\n    'data.zarr',\n    mode='w',\n    shape=data.shape,\n    chunks=(10, 512, 512),\n    dtype='int16',\n    compressor=AnscombeTransformV2(\n        zero_level=100,\n        conversion_gain=2.5\n    )\n)\n\n# Write and read\narr[:] = data\nrecovered = arr[:]\n</code></pre>"},{"location":"user-guide/zarr-v2/#using-with-additional-compression","title":"Using with Additional Compression","text":"<p>In Zarr V2, the Anscombe codec can be combined with other compressors by nesting them:</p> <pre><code>from numcodecs import Blosc\nfrom anscombe_transform import AnscombeTransformV2\n\n# Note: Zarr V2 doesn't support filter chains natively\n# The Anscombe codec must be the primary compressor\ncompressor = AnscombeTransformV2(\n    zero_level=100,\n    conversion_gain=2.5,\n    encoded_dtype='uint8'\n)\n\narr = zarr.open_array(\n    'compressed.zarr',\n    mode='w',\n    shape=(100, 512, 512),\n    chunks=(10, 512, 512),\n    dtype='int16',\n    compressor=compressor\n)\n</code></pre> <p>Limitation</p> <p>Zarr V2 doesn't support filter chains like V3 does. The Anscombe codec serves as both the transform and the compressor. For better compression with additional algorithms, consider upgrading to Zarr V3.</p>"},{"location":"user-guide/zarr-v2/#codec-parameters","title":"Codec Parameters","text":""},{"location":"user-guide/zarr-v2/#required-parameters","title":"Required Parameters","text":"<ul> <li><code>zero_level</code> (float): Baseline signal with no photons</li> <li><code>conversion_gain</code> (float): Signal units per photon (also called <code>photon_sensitivity</code>)</li> </ul>"},{"location":"user-guide/zarr-v2/#optional-parameters","title":"Optional Parameters","text":"<ul> <li><code>encoded_dtype</code> (str or dtype): Data type for encoded values, default: <code>'uint8'</code></li> <li>Use <code>'uint8'</code> for maximum compression (0-255 range)</li> <li>Use <code>'uint16'</code> for higher dynamic range</li> <li><code>decoded_dtype</code> (str or dtype): Data type for decoded output, default: inferred from input</li> </ul>"},{"location":"user-guide/zarr-v2/#codec-registration","title":"Codec Registration","text":"<p>The codec is automatically registered when you import it:</p> <pre><code>from anscombe_transform import AnscombeTransformV2\nimport numcodecs\n\n# The codec is now registered\ncodec = numcodecs.get_codec({'id': 'anscombe-v1', 'zero_level': 100, 'conversion_gain': 2.5})\n</code></pre>"},{"location":"user-guide/zarr-v2/#serialization","title":"Serialization","text":"<p>The codec can be serialized to/from JSON:</p> <pre><code>from anscombe_transform import AnscombeTransformV2\n\n# Create codec\ncodec = AnscombeTransformV2(zero_level=100, conversion_gain=2.5)\n\n# Serialize to dict\nconfig = codec.get_config()\nprint(config)\n# {'id': 'anscombe-v1', 'zero_level': 100, 'conversion_gain': 2.5, ...}\n\n# Deserialize from dict\ncodec2 = AnscombeTransformV2.from_config(config)\n</code></pre> <p>This is useful for: - Storing codec configuration in metadata - Sharing compression settings across systems - Programmatic codec creation</p>"},{"location":"user-guide/zarr-v2/#working-with-existing-arrays","title":"Working with Existing Arrays","text":""},{"location":"user-guide/zarr-v2/#reading-compressed-data","title":"Reading Compressed Data","text":"<p>If data was compressed with the Anscombe codec:</p> <pre><code>import zarr\nfrom anscombe_transform import AnscombeTransformV2\n\n# Open existing array (codec info is stored in .zarray metadata)\narr = zarr.open_array('data.zarr', mode='r')\n\n# Read data (automatically decompressed)\ndata = arr[:]\n</code></pre>"},{"location":"user-guide/zarr-v2/#inspecting-codec-configuration","title":"Inspecting Codec Configuration","text":"<pre><code>import zarr\nimport json\n\n# Read .zarray metadata\nwith open('data.zarr/.zarray', 'r') as f:\n    metadata = json.load(f)\n\nprint(metadata['compressor'])\n# {'id': 'anscombe-v1', 'zero_level': 100, 'conversion_gain': 2.5, ...}\n</code></pre>"},{"location":"user-guide/zarr-v2/#migration-to-zarr-v3","title":"Migration to Zarr V3","text":"<p>To migrate data from V2 to V3:</p> <pre><code>import zarr\nfrom anscombe_transform import AnscombeTransformV2, AnscombeTransformV3\n\n# Open V2 array\nv2_arr = zarr.open_array('data_v2.zarr', mode='r')\n\n# Get codec config\nv2_config = v2_arr.compressor.get_config()\n\n# Create V3 array with equivalent codec\nv3_arr = zarr.create(\n    shape=v2_arr.shape,\n    chunks=v2_arr.chunks,\n    dtype=v2_arr.dtype,\n    filters=[AnscombeTransformV3(\n        zero_level=v2_config['zero_level'],\n        conversion_gain=v2_config['conversion_gain']\n    )],\n    zarr_format=3\n)\n\n# Copy data\nv3_arr[:] = v2_arr[:]\n</code></pre>"},{"location":"user-guide/zarr-v2/#api-reference","title":"API Reference","text":"<p>See the Codec API Reference for detailed documentation of all parameters and methods.</p>"},{"location":"user-guide/zarr-v2/#next-steps","title":"Next Steps","text":"<ul> <li>Zarr V3 Integration - Learn about the improved V3 interface</li> <li>Parameter Estimation - Estimate codec parameters from data</li> <li>Examples - See complete examples</li> </ul>"},{"location":"user-guide/zarr-v3/","title":"Zarr V3 Integration","text":"<p>This guide covers using the Anscombe Transform codec with Zarr V3, which provides improved performance and flexibility.</p>"},{"location":"user-guide/zarr-v3/#basic-usage","title":"Basic Usage","text":"<pre><code>import zarr\nimport numpy as np\nfrom anscombe_transform import AnscombeTransformV3\n\n# Create data\ndata = np.random.poisson(lam=50, size=(100, 512, 512)).astype('int16')\n\n# Create Zarr V3 array with Anscombe codec as a filter\nstore = zarr.storage.MemoryStore()\narr = zarr.create(\n    store=store,\n    shape=data.shape,\n    chunks=(10, 512, 512),\n    dtype='int16',\n    filters=[AnscombeTransformV3(\n        zero_level=100,\n        conversion_gain=2.5\n    )],\n    zarr_format=3\n)\n\n# Write and read\narr[:] = data\nrecovered = arr[:]\n</code></pre>"},{"location":"user-guide/zarr-v3/#filter-chains","title":"Filter Chains","text":"<p>Zarr V3 supports filter chains, allowing you to combine the Anscombe transform with other compression algorithms:</p> <pre><code>import zarr\nfrom anscombe_transform import AnscombeTransformV3\n\n# Use Anscombe as a filter with Blosc compression\narr = zarr.create(\n    shape=(100, 512, 512),\n    chunks=(10, 512, 512),\n    dtype='int16',\n    filters=[\n        AnscombeTransformV3(zero_level=100, conversion_gain=2.5)\n    ],\n    compressor={\n        'id': 'blosc',\n        'cname': 'zstd',\n        'clevel': 5,\n        'shuffle': 'bitshuffle'\n    },\n    zarr_format=3\n)\n</code></pre> <p>The processing pipeline is: 1. Original data (int16) 2. Anscombe filter \u2192 transformed data (uint8) 3. Blosc compressor \u2192 compressed bytes 4. Storage</p>"},{"location":"user-guide/zarr-v3/#recommended-compressors","title":"Recommended Compressors","text":"<p>Different compressors work well with the Anscombe-transformed data:</p>"},{"location":"user-guide/zarr-v3/#blosc-with-zstd-best-overall","title":"Blosc with Zstd (Best Overall)","text":"<pre><code>filters = [AnscombeTransformV3(zero_level=100, conversion_gain=2.5)]\ncompressor = {\n    'id': 'blosc',\n    'cname': 'zstd',      # Excellent compression + speed\n    'clevel': 5,          # Compression level (1-9)\n    'shuffle': 'bitshuffle'\n}\n</code></pre>"},{"location":"user-guide/zarr-v3/#blosc-with-lz4-fastest","title":"Blosc with LZ4 (Fastest)","text":"<pre><code>compressor = {\n    'id': 'blosc',\n    'cname': 'lz4',       # Fastest decompression\n    'clevel': 3,\n    'shuffle': 'bitshuffle'\n}\n</code></pre>"},{"location":"user-guide/zarr-v3/#blosc-with-zlib-maximum-compression","title":"Blosc with Zlib (Maximum Compression)","text":"<pre><code>compressor = {\n    'id': 'blosc',\n    'cname': 'zlib',      # Best compression ratio\n    'clevel': 9,\n    'shuffle': 'bitshuffle'\n}\n</code></pre>"},{"location":"user-guide/zarr-v3/#codec-parameters","title":"Codec Parameters","text":""},{"location":"user-guide/zarr-v3/#required-parameters","title":"Required Parameters","text":"<ul> <li><code>zero_level</code> (float): Baseline signal with no photons</li> <li><code>conversion_gain</code> (float): Signal units per photon</li> </ul>"},{"location":"user-guide/zarr-v3/#optional-parameters","title":"Optional Parameters","text":"<ul> <li><code>encoded_dtype</code> (str or dtype): Data type for encoded values, default: <code>'uint8'</code></li> <li><code>decoded_dtype</code> (str or dtype): Data type for decoded output, default: inferred</li> <li><code>beta</code> (float): Quantization step size in noise standard deviations, default: <code>0.5</code></li> </ul>"},{"location":"user-guide/zarr-v3/#advanced-beta-parameter","title":"Advanced: Beta Parameter","text":"<p>The <code>beta</code> parameter controls the quantization precision:</p> <pre><code># Finer quantization (more levels, better accuracy, less compression)\ncodec_fine = AnscombeTransformV3(\n    zero_level=100,\n    conversion_gain=2.5,\n    beta=0.25  # Half the default step size\n)\n\n# Coarser quantization (fewer levels, more compression, lower accuracy)\ncodec_coarse = AnscombeTransformV3(\n    zero_level=100,\n    conversion_gain=2.5,\n    beta=1.0  # Double the default step size\n)\n</code></pre> <p>Default <code>beta=0.5</code> means each quantization level represents 0.5 standard deviations of noise, which is a good balance for most applications.</p>"},{"location":"user-guide/zarr-v3/#codec-registration","title":"Codec Registration","text":"<p>The codec is automatically registered with Zarr V3:</p> <pre><code>from anscombe_transform import AnscombeTransformV3\nimport zarr\n\n# Check if registered\nprint('anscombe-v1' in zarr.codecs.registry.get_codec_class('anscombe-v1'))\n</code></pre>"},{"location":"user-guide/zarr-v3/#serialization-and-metadata","title":"Serialization and Metadata","text":""},{"location":"user-guide/zarr-v3/#codec-configuration","title":"Codec Configuration","text":"<p>The codec configuration is stored in the array metadata:</p> <pre><code>import zarr\nfrom anscombe_transform import AnscombeTransformV3\n\n# Create array\narr = zarr.create(\n    shape=(100, 512, 512),\n    dtype='int16',\n    filters=[AnscombeTransformV3(zero_level=100, conversion_gain=2.5)],\n    zarr_format=3\n)\n\n# Access metadata\nprint(arr.metadata)\n</code></pre>"},{"location":"user-guide/zarr-v3/#json-serialization","title":"JSON Serialization","text":"<pre><code>from anscombe_transform import AnscombeTransformV3\n\ncodec = AnscombeTransformV3(zero_level=100, conversion_gain=2.5)\n\n# Convert to dict\nconfig = codec.to_dict()\nprint(config)\n# {'name': 'anscombe-v1', 'configuration': {'zero_level': 100, ...}}\n\n# Reconstruct from dict\ncodec2 = AnscombeTransformV3.from_dict(config)\n</code></pre>"},{"location":"user-guide/zarr-v3/#performance-optimization","title":"Performance Optimization","text":""},{"location":"user-guide/zarr-v3/#chunk-size-selection","title":"Chunk Size Selection","text":"<p>Choose chunk sizes that balance compression and access patterns:</p> <pre><code># For sequential access (e.g., video playback)\nchunks = (10, 512, 512)  # 10 frames at a time\n\n# For random time-point access\nchunks = (1, 512, 512)   # Single frames\n\n# For spatial crops across time\nchunks = (100, 128, 128) # Smaller spatial regions, all time points\n</code></pre>"},{"location":"user-guide/zarr-v3/#parallel-processing","title":"Parallel Processing","text":"<p>Zarr V3 supports parallel chunk processing:</p> <pre><code>import zarr\nfrom concurrent.futures import ThreadPoolExecutor\n\narr = zarr.open_array('data.zarr', mode='r')\n\n# Read chunks in parallel\nwith ThreadPoolExecutor(max_workers=4) as executor:\n    futures = []\n    for i in range(0, arr.shape[0], 10):\n        future = executor.submit(lambda i=i: arr[i:i+10])\n        futures.append(future)\n\n    results = [f.result() for f in futures]\n</code></pre>"},{"location":"user-guide/zarr-v3/#working-with-different-storage-backends","title":"Working with Different Storage Backends","text":""},{"location":"user-guide/zarr-v3/#local-filesystem","title":"Local Filesystem","text":"<pre><code>import zarr\nfrom anscombe_transform import AnscombeTransformV3\n\nstore = zarr.storage.LocalStore('data.zarr')\narr = zarr.create(\n    store=store,\n    shape=(100, 512, 512),\n    filters=[AnscombeTransformV3(zero_level=100, conversion_gain=2.5)],\n    zarr_format=3\n)\n</code></pre>"},{"location":"user-guide/zarr-v3/#in-memory","title":"In-Memory","text":"<pre><code>store = zarr.storage.MemoryStore()\narr = zarr.create(\n    store=store,\n    shape=(100, 512, 512),\n    filters=[AnscombeTransformV3(zero_level=100, conversion_gain=2.5)],\n    zarr_format=3\n)\n</code></pre>"},{"location":"user-guide/zarr-v3/#remote-storage-s3-gcs","title":"Remote Storage (S3, GCS)","text":"<pre><code>import zarr\nfrom anscombe_transform import AnscombeTransformV3\n\n# Requires fsspec and s3fs/gcsfs\nstore = zarr.storage.RemoteStore('s3://bucket/data.zarr')\narr = zarr.create(\n    store=store,\n    shape=(100, 512, 512),\n    filters=[AnscombeTransformV3(zero_level=100, conversion_gain=2.5)],\n    zarr_format=3\n)\n</code></pre>"},{"location":"user-guide/zarr-v3/#api-reference","title":"API Reference","text":"<p>See the Codec API Reference for detailed documentation.</p>"},{"location":"user-guide/zarr-v3/#next-steps","title":"Next Steps","text":"<ul> <li>Parameter Estimation - Estimate codec parameters</li> <li>Examples - Complete workflow examples</li> <li>Zarr V2 Integration - If you need V2 compatibility</li> </ul>"}]}